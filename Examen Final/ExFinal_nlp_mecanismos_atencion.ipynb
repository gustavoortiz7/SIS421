{"cells":[{"cell_type":"markdown","metadata":{"id":"Yg90deR13qYE"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/041_attention/attention.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"4Kzp2jHl3qY7"},"source":["# Mecanismos de Atención"]},{"cell_type":"markdown","metadata":{"id":"Uv20V-KqDhH6"},"source":["En el [post](https://sensioai.com/blog/040_encoder_decoder) anterior aprendimos a implementar una arquitectura de red neuronal conocida como `seq2seq`, que utiliza dos redes neuronales (el `encoder` y el `decoder`) para poder trabajar con secuencias de longitud arbitraria tanto a sus entradas como en las salidas. Este modelo nos permite llevar a cabo tareas tales como la traducción de texto entre dos idiomas, resumir un texto, responder preguntas, etc.\n","\n","![](https://pytorch.org/tutorials/_images/seq2seq.png)\n","\n","Si bien este modelo nos dio buenos resultados, podemos mejorarlo. Si prestamos atención a la arquitectura que desarrollamos, el `decoder` (encargado de generar la secuencia de salida) es inicializado con el último estado oculto del `encoder`, el cual tiene la responsabilidad de codificar el significado de toda la frase original. Esto puede ser complicado, sobre todo al trabajar con secuencias muy largas, y para solventar este problema podemos utilizar un mecanismo de `atención` que no solo reciba el último estado oculto si no también tenga acceso a todas las salidas del `encoder` de manera que el `decoder` sea capaz de \"focalizar su atención\" en aquellas partes más importantes. Por ejemplo, para traducir la primera palabra es lógico pensar que lo más importante será la primera palabra y sus adyacentes en la frase original, pero usar el último estado oculto del `encoder` puede no ser suficiente para mantener estas relaciones a largo plazo. Permitir al `decoder` acceder a esta información puede resultar en mejores prestaciones."]},{"cell_type":"markdown","metadata":{"id":"eGFyd0UgDhH7"},"source":["> 💡 En la práctica, los mecanismos de atención dan muy buenos resultados en tareas que envuelvan datos secuenciales (como aplicaciones de lenguaje). De hecho, los mejores modelos a día de hoy para tareas de `NLP` no están basados en redes recurrentes sino en arquitecturas que únicamente implementan mecanismos de atención en varias capas. Estas redes neuronales son conocidas como `Transformers`."]},{"cell_type":"markdown","metadata":{"id":"WtdizuVTDhH7"},"source":["## El *dataset*"]},{"cell_type":"markdown","metadata":{"id":"daTZSHr8DhH8"},"source":["Vamos a resolver exactamente el mismo caso que en el post anterior, así que todo lo que hace referencia al procesado de datos lo dejaremos igual."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5glMxTtMs_F","outputId":"97da59a8-b1c5-4eac-8bcb-adb5f53d0b3e","executionInfo":{"status":"ok","timestamp":1687524620968,"user_tz":240,"elapsed":20699,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"jjx2B4Q3DhH8","executionInfo":{"status":"ok","timestamp":1687524620968,"user_tz":240,"elapsed":3,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":["import unicodedata\n","import re\n","\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    return s\n","\n","def read_file(file, reverse=False):\n","    # Read the file and split into lines\n","    lines = open(file, encoding='utf-8').read().strip().split('\\n')\n","\n","    # Split every line into pairs and normalize\n","    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n","\n","    return pairs"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"iuI67myQDhH-","executionInfo":{"status":"ok","timestamp":1687524621288,"user_tz":240,"elapsed":322,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":["pairs = read_file('/content/drive/MyDrive/SIS421/EXAMENFINAL/dialogos.txt')\n","#pairs = read_file('spa.txt')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"onkJ27fWDhH-","outputId":"823a987b-7d12-4ea4-edbe-028c1f06b0e8","executionInfo":{"status":"ok","timestamp":1687524621593,"user_tz":240,"elapsed":308,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["['hi how are you doing ?', 'i m fine . how about yourself ?']\n","Pregunta: hi how are you doing ?\n","Respuesta: i m fine . how about yourself ?\n"]}],"source":["import random\n","\n","#random.choice(pairs)\n","print(pairs[0] )\n","\n","# Mostrar el primer par de preguntas y respuestas\n","first_pair = pairs[0]\n","pregunt = first_pair[0]\n","respuest = first_pair[1]\n","\n","print(\"Pregunta:\", pregunt)\n","print(\"Respuesta:\", respuest)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"nlP5chOyDhH_","executionInfo":{"status":"ok","timestamp":1687524621594,"user_tz":240,"elapsed":5,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":["SOS_token = 0\n","EOS_token = 1\n","PAD_token = 2\n","\n","class Lang:\n","    def __init__(self, language):\n","        self.language = language\n","        self.word2id = {\"SOS\": 0, \"EOS\": 1, \"PAD\": 2}\n","        self.word2count = {}\n","        self.id2word = {0: \"SOS\", 1: \"EOS\", 2: \"PAD\"}\n","        self.n_words = 3  # Count SOS, EOS and PAD\n","\n","    def addQuestion(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2id:\n","            self.word2id[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.id2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1\n","\n","    def idsFromQuestion(self, sentence):\n","        return [self.word2id[word] for word in sentence.split(' ')]\n","\n","    def questionFromIds(self, index):\n","        return [self.id2word[ix] for ix in index]"]},{"cell_type":"markdown","metadata":{"id":"GFa0Pg3mDhIA"},"source":["Para poder aplicar la capa de `attention` necesitamos que nuestras frases tengan una longitud máxima definida."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"bqBjVo-fDhIA","executionInfo":{"status":"ok","timestamp":1687524621594,"user_tz":240,"elapsed":4,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":["MAX_LENGTH = 20\n","def filterPairs(pairs, filters, lang=0):\n","    return pairs\n","def trimPairs(pairs):\n","    return [p for p in pairs if len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH]"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p0xlL2RpDhIB","outputId":"b8803048-c6d2-485b-99e0-84d9320bfd8b","executionInfo":{"status":"ok","timestamp":1687524621931,"user_tz":240,"elapsed":341,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Tenemos 3725 pares de frases\n","Tenemos 3712 pares de frases con longitud menor de 20\n","Longitud vocabularios:\n","question 2285\n","answer 2339\n"]},{"output_type":"execute_result","data":{"text/plain":["['tomorrow i m going to buy an electric sharpener . EOS',\n"," 'get one with the rubber suction cups on the bottom . EOS']"]},"metadata":{},"execution_count":7}],"source":["def prepareData(file, filters=None, reverse=False):\n","\n","    pairs = read_file(file, reverse)\n","    print(f\"Tenemos {len(pairs)} pares de frases\")\n","\n","    pairs = trimPairs(pairs)\n","    print(f\"Tenemos {len(pairs)} pares de frases con longitud menor de {MAX_LENGTH}\")\n","\n","    # Reverse pairs, make Lang instances\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","        question_lang = Lang('answer')\n","        answer_lang = Lang('question')\n","    else:\n","        question_lang = Lang('question')\n","        answer_lang = Lang('answer')\n","\n","    for pair in pairs:\n","        question_lang.addQuestion(pair[0])\n","        answer_lang.addQuestion(pair[1])\n","\n","        # add <eos> token\n","        pair[0] += \" EOS\"\n","        pair[1] += \" EOS\"\n","\n","    print(\"Longitud vocabularios:\")\n","    print(question_lang.language, question_lang.n_words)\n","    print(answer_lang.language, answer_lang.n_words)\n","\n","    return question_lang, answer_lang, pairs\n","\n","question_lang, answer_lang, pairs = prepareData('/content/drive/MyDrive/SIS421/EXAMENFINAL/dialogos.txt')\n","\n","# descomentar para usar el dataset filtrado\n","#question_lang, answer_lang, pairs = prepareData('spa.txt', filters=eng_prefixes)\n","\n","random.choice(pairs)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4adczw9qDhIB","outputId":"92d6bcef-7b6f-4c3f-ae15-f060e1c25a5b","scrolled":true,"executionInfo":{"status":"ok","timestamp":1687524621932,"user_tz":240,"elapsed":5,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[24, 26, 29, 20, 30, 31, 6]"]},"metadata":{},"execution_count":8}],"source":["answer_lang.idsFromQuestion('what school do you go to .')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tKV0Hk3JDhIC","outputId":"a450c845-9c4e-4135-b2e4-f638a6f46ec9","executionInfo":{"status":"ok","timestamp":1687524621932,"user_tz":240,"elapsed":3,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i', 'wonder', 'poodle', 'fine']"]},"metadata":{},"execution_count":9}],"source":["answer_lang.questionFromIds([3, 1028, 647, 5])"]},{"cell_type":"markdown","metadata":{"id":"2g6d3FnUDhIC"},"source":["En el `Dataset` nos aseguraremos de añadir el *padding* necesario para que todas las frases tengan la misma longitud, lo cual no hace necesario utilizar la función `collate` que implementamos en el post anterior."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zi3oPVr7DhIC","outputId":"528ef3b3-bddc-4a1b-b693-1b52ea0bf1e8","executionInfo":{"status":"ok","timestamp":1687524627574,"user_tz":240,"elapsed":5644,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2969, 743)"]},"metadata":{},"execution_count":10}],"source":["import torch\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, question_lang, answer_lang, pairs, max_length):\n","        self.question_lang = question_lang\n","        self.answer_lang = answer_lang\n","        self.pairs = pairs\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.pairs)\n","\n","    def __getitem__(self, ix):\n","        inputs = torch.tensor(self.question_lang.idsFromQuestion(self.pairs[ix][0]), device=device, dtype=torch.long)\n","        outputs = torch.tensor(self.answer_lang.idsFromQuestion(self.pairs[ix][1]), device=device, dtype=torch.long)\n","        # metemos padding a todas las frases hast a la longitud máxima\n","        return torch.nn.functional.pad(inputs, (0, self.max_length - len(inputs)), 'constant', self.question_lang.word2id['PAD']), \\\n","            torch.nn.functional.pad(outputs, (0, self.max_length - len(outputs)), 'constant', self.answer_lang.word2id['PAD'])\n","\n","# separamos datos en train-test\n","train_size = len(pairs) * 80 // 100\n","train = pairs[:train_size]\n","test = pairs[train_size:]\n","\n","dataset = {\n","    'train': Dataset(question_lang, answer_lang, train, max_length=MAX_LENGTH),\n","    'test': Dataset(question_lang, answer_lang, test, max_length=MAX_LENGTH)\n","}\n","\n","len(dataset['train']), len(dataset['test'])"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NI-4eXBzDhID","outputId":"b743230f-ed20-458d-c627-9f6cad8ca8bb","executionInfo":{"status":"ok","timestamp":1687524627574,"user_tz":240,"elapsed":6,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([3, 4, 5, 6, 7, 8, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n"," tensor([ 3,  4,  5,  6,  7,  8,  9, 10,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n","          2,  2]))"]},"metadata":{},"execution_count":11}],"source":["question_sentence, answer_sentence = dataset['train'][0]\n","\n","question_sentence, answer_sentence"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkC8KTkXDhID","outputId":"acb249e5-cf26-4e4f-b0c7-86f7cb7bc3b9","executionInfo":{"status":"ok","timestamp":1687524627575,"user_tz":240,"elapsed":5,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['hi',\n","  'how',\n","  'are',\n","  'you',\n","  'doing',\n","  '?',\n","  'EOS',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD'],\n"," ['i',\n","  'm',\n","  'fine',\n","  '.',\n","  'how',\n","  'about',\n","  'EOS',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD'])"]},"metadata":{},"execution_count":12}],"source":["question_lang.questionFromIds(question_sentence.tolist()), answer_lang.questionFromIds(question_sentence.tolist())"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSMTf916DhID","outputId":"3707da84-b3b8-4af4-a7fd-a90ab9fc0143","executionInfo":{"status":"ok","timestamp":1687524627575,"user_tz":240,"elapsed":4,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[  9,  10, 788,  ...,   2,   2,   2],\n","        [214, 106,  34,  ...,   2,   2,   2],\n","        [369, 123, 244,  ...,   2,   2,   2],\n","        ...,\n","        [255,   6, 167,  ...,   2,   2,   2],\n","        [907, 610, 906,  ...,   2,   2,   2],\n","        [256, 241,  39,  ...,   2,   2,   2]])\n"]}],"source":["dataloader = {\n","    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=64, shuffle=True),\n","    'test': torch.utils.data.DataLoader(dataset['test'], batch_size=128, shuffle=False),\n","}\n","\n","inputs, outputs = next(iter(dataloader['train']))\n","inputs.shape, outputs.shape\n","print(inputs)"]},{"cell_type":"markdown","metadata":{"id":"blqqT_eRDhIE"},"source":["## El modelo"]},{"cell_type":"markdown","metadata":{"id":"dkdKVyp7DhIE"},"source":["En lo que se refiere al `encoder`, seguimos usando exactamente la misma arquitectura. La única diferencia es que, además del último estado oculto, necesitaremos todas sus salidas para que el `decoder` pueda usarlas."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"ltJt9863DhIE","executionInfo":{"status":"ok","timestamp":1687524829068,"user_tz":240,"elapsed":283,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":["class Encoder(torch.nn.Module):\n","    def __init__(self, input_size, embedding_size=128, hidden_size=128, n_layers=5):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n","        self.gru = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n","\n","    def forward(self, input_sentences):\n","        embedded = self.embedding(input_sentences)\n","        outputs, hidden = self.gru(embedded)\n","        return outputs, hidden\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xNp_995_DhIE","outputId":"422b0b35-b1ce-43c6-ac3f-b02111ffba1a","executionInfo":{"status":"ok","timestamp":1687524835879,"user_tz":240,"elapsed":280,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 20, 128])"]},"metadata":{},"execution_count":25}],"source":["encoder = Encoder(input_size=question_lang.n_words)\n","encoder_outputs, encoder_hidden = encoder(torch.randint(0, question_lang.n_words, (64, 20)))\n","\n","# [batch size, seq len, hidden size]\n","encoder_outputs.shape"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJPUWzuuDhIF","outputId":"081253c1-be1c-4d98-f83a-4aa636af8e7e","executionInfo":{"status":"ok","timestamp":1687524838223,"user_tz":240,"elapsed":2,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([5, 64, 128])"]},"metadata":{},"execution_count":26}],"source":["# [num layers, batch size, hidden size]\n","encoder_hidden.shape"]},{"cell_type":"markdown","metadata":{"id":"do1BYr7iDhIF"},"source":["### El *decoder* con *attention*"]},{"cell_type":"markdown","metadata":{"id":"EbSny1MIDhIF"},"source":["Vamos a ver un ejemplo de implementación de una capa de atención para nuestro `decoder`. En primer lugar tendremos una capa lineal que recibirá como entradas los `embeddings` y el estado oculto anterior (concatenados). Esta capa lineal nos dará a la salida tantos valores como elementos tengamos en nuestras secuencias de entrada (recuerda que las hemos forzado a tener una longitud determinada). Después, aplicaremos una función `softmax` sobre estos valores obteniendo así una distribución de probabilidad que, seguidamente, multiplicaremos por los *outputs* del encoder (que también tienen la misma longitud). En esta función de probabilidad, cada elemento tiene un valor entre 0 y 1. Así pues, esta operación dará más importancia a aquellos *outputs* del `encoder` más importantes mientras que al resto les asignará unos valores cercanos a 0. A continuación, concatenaremos estos valores con los `embeddings`, de nuevo, y se lo daremos a una nueva capa lineal que combinará estos `embeddings` con los *outputs* del `encoder` re-escalados para obtener así los *inputs* finales de la capa recurrente.\n","\n","En resumen, usaremos las entradas y estado oculto del `decoder` para encontrar unos pesos que re-escalarán las salidas del `encoder`, los cuales combinaremos de nuevo con las entradas del `decoder` para obtener las representaciones finales de nuestras frases que alimentan la capa recurrente.\n","\n","![](https://i.imgur.com/1152PYf.png)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"CzsdfrcnqlA7","executionInfo":{"status":"ok","timestamp":1687524858685,"user_tz":240,"elapsed":299,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":["class DialogDecoder(torch.nn.Module):\n","    def __init__(self, input_size, embedding_size=128, hidden_size=128, n_layers=5, max_length=MAX_LENGTH):\n","        super().__init__()\n","\n","        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n","        self.gru = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n","        self.out = torch.nn.Linear(hidden_size, input_size)\n","\n","        # attention\n","        self.attn = torch.nn.Linear(hidden_size + embedding_size, max_length)\n","        self.attn_combine = torch.nn.Linear(hidden_size * 2, hidden_size)\n","\n","    def forward(self, input_dialogue, hidden, encoder_outputs):\n","        # Obtenemos los embeddings de los turnos de diálogo\n","        embedded = self.embedding(input_dialogue)\n","\n","        # Calculamos los pesos de atención entre los turnos de diálogo y el estado oculto anterior\n","        attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n","        uno=attn_weights.unsqueeze(1)\n","\n","        # Realizamos la atención entre los turnos de diálogo y el encoder_outputs\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n","        # Concatenamos los embeddings con la atención aplicada\n","        output = torch.cat((embedded.squeeze(1), attn_applied.squeeze(1)), 1)\n","        output = self.attn_combine(output)\n","        output = torch.nn.functional.relu(output)\n","\n","        # Aplicamos la capa GRU con la entrada ajustada\n","        output, hidden = self.gru(output.unsqueeze(1), hidden)\n","\n","        # Generamos la salida final\n","        output = self.out(output.squeeze(1))\n","\n","        return output, hidden, attn_weights\n","\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXAw3xHpDhIF","outputId":"8de257e9-572d-4495-e242-be49a5f1e948","executionInfo":{"status":"ok","timestamp":1687524864462,"user_tz":240,"elapsed":325,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-27-c73859c09972>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 2339])"]},"metadata":{},"execution_count":28}],"source":["decoder = DialogDecoder(input_size=answer_lang.n_words)\n","decoder_output, decoder_hidden, attn_weights = decoder(torch.randint(0, answer_lang.n_words, (64,1)), encoder_hidden, encoder_outputs)\n","\n","# [batch size, vocab size]\n","decoder_output.shape"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JwlFc-8zDhIG","outputId":"cf4e8c69-4c15-43c9-c1c3-c4841474c93e","executionInfo":{"status":"ok","timestamp":1687524871806,"user_tz":240,"elapsed":288,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([5, 64, 128])"]},"metadata":{},"execution_count":29}],"source":["# [num layers, batch size, hidden size]\n","decoder_hidden.shape"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FW_BF-feDhIG","outputId":"142c5414-9130-4245-f2ca-d7b66fd3ebf0","executionInfo":{"status":"ok","timestamp":1687524873906,"user_tz":240,"elapsed":291,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 20])"]},"metadata":{},"execution_count":30}],"source":["# [batch size, max_length]\n","attn_weights.shape"]},{"cell_type":"markdown","metadata":{"id":"XfgvaCeWDhIG"},"source":["## Entrenamiento"]},{"cell_type":"markdown","metadata":{"id":"ypR81P5sDhIG"},"source":["Vamos a implementar el bucle de entrenamiento. En primer lugar, al tener ahora dos redes neuronales, necesitaremos dos optimizadores (uno para el `encoder` y otro para el `decoder`). Al `encoder` le pasaremos la frase en el idioma original, y obtendremos el estado oculto final. Este estado oculto lo usaremos para inicializar el `decoder` que, junto al token `<sos>`, generará la primera palabra de la frase traducida. Repetiremos el proceso, utilizando como entrada la anterior salida del decoder, hasta obtener el token `<eos>`."]},{"cell_type":"code","execution_count":31,"metadata":{"id":"QDu8VoLqDhIG","executionInfo":{"status":"ok","timestamp":1687524880728,"user_tz":240,"elapsed":2,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":["from tqdm import tqdm\n","import numpy as np\n","\n","def fit(encoder, decoder, dataloader, epochs=10):\n","    encoder.to(device)\n","    decoder.to(device)\n","    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n","    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n","    #criterion = torch.nn.functional.cross_entropy()\n","    criterion = torch.nn.CrossEntropyLoss()\n","    for epoch in range(1, epochs+1):\n","        encoder.train()\n","        decoder.train()\n","        train_loss = []\n","        bar = tqdm(dataloader['train'])\n","        for batch in bar:\n","            input_sentences, output_sentences = batch\n","            bs = input_sentences.shape[0]\n","            loss = 0\n","            encoder_optimizer.zero_grad()\n","            decoder_optimizer.zero_grad()\n","            # obtenemos el último estado oculto del encoder\n","            encoder_outputs, hidden = encoder(input_sentences)\n","            # calculamos las salidas del decoder de manera recurrente\n","            decoder_input = torch.tensor([[answer_lang.word2id['SOS']] for b in range(bs)], device=device)\n","            for i in range(output_sentences.shape[1]):\n","                output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n","                loss += criterion(output, output_sentences[:, i].view(bs))\n","                # el siguiente input será la palabra predicha\n","                decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n","            # optimización\n","            loss.backward()\n","            encoder_optimizer.step()\n","            decoder_optimizer.step()\n","            train_loss.append(loss.item())\n","            bar.set_description(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f}\")\n","\n","        val_loss = []\n","        encoder.eval()\n","        decoder.eval()\n","        with torch.no_grad():\n","            bar = tqdm(dataloader['test'])\n","            for batch in bar:\n","                input_sentences, output_sentences = batch\n","                bs = input_sentences.shape[0]\n","                loss = 0\n","                # obtenemos el último estado oculto del encoder\n","                encoder_outputs, hidden = encoder(input_sentences)\n","                # calculamos las salidas del decoder de manera recurrente\n","                decoder_input = torch.tensor([[answer_lang.word2id['SOS']] for b in range(bs)], device=device)\n","                for i in range(output_sentences.shape[1]):\n","                    output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n","                    loss += criterion(output, output_sentences[:, i].view(bs))\n","                    # el siguiente input será la palabra predicha\n","                    decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n","                val_loss.append(loss.item())\n","                bar.set_description(f\"Epoch {epoch}/{epochs} val_loss {np.mean(val_loss):.5f}\")"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bwNeQeLGDhIH","outputId":"a58ba236-f02f-4dad-c3d7-3aee512820a2","executionInfo":{"status":"ok","timestamp":1687527069988,"user_tz":240,"elapsed":2182534,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/47 [00:00<?, ?it/s]<ipython-input-27-c73859c09972>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n","Epoch 1/100 loss 72.75503: 100%|██████████| 47/47 [00:19<00:00,  2.39it/s]\n","Epoch 1/100 val_loss 56.95077: 100%|██████████| 6/6 [00:01<00:00,  4.62it/s]\n","Epoch 2/100 loss 51.25962: 100%|██████████| 47/47 [00:21<00:00,  2.19it/s]\n","Epoch 2/100 val_loss 56.31011: 100%|██████████| 6/6 [00:01<00:00,  4.47it/s]\n","Epoch 3/100 loss 50.42215: 100%|██████████| 47/47 [00:20<00:00,  2.33it/s]\n","Epoch 3/100 val_loss 56.56576: 100%|██████████| 6/6 [00:01<00:00,  3.91it/s]\n","Epoch 4/100 loss 50.18298: 100%|██████████| 47/47 [00:21<00:00,  2.22it/s]\n","Epoch 4/100 val_loss 56.39416: 100%|██████████| 6/6 [00:01<00:00,  4.59it/s]\n","Epoch 5/100 loss 49.80697: 100%|██████████| 47/47 [00:19<00:00,  2.40it/s]\n","Epoch 5/100 val_loss 56.50121: 100%|██████████| 6/6 [00:01<00:00,  4.40it/s]\n","Epoch 6/100 loss 49.75793: 100%|██████████| 47/47 [00:21<00:00,  2.22it/s]\n","Epoch 6/100 val_loss 56.47331: 100%|██████████| 6/6 [00:01<00:00,  4.61it/s]\n","Epoch 7/100 loss 49.50781: 100%|██████████| 47/47 [00:19<00:00,  2.39it/s]\n","Epoch 7/100 val_loss 56.50900: 100%|██████████| 6/6 [00:01<00:00,  4.56it/s]\n","Epoch 8/100 loss 49.28317: 100%|██████████| 47/47 [00:21<00:00,  2.22it/s]\n","Epoch 8/100 val_loss 57.54175: 100%|██████████| 6/6 [00:01<00:00,  4.63it/s]\n","Epoch 9/100 loss 48.83863: 100%|██████████| 47/47 [00:19<00:00,  2.39it/s]\n","Epoch 9/100 val_loss 56.84376: 100%|██████████| 6/6 [00:01<00:00,  4.57it/s]\n","Epoch 10/100 loss 48.54048: 100%|██████████| 47/47 [00:21<00:00,  2.22it/s]\n","Epoch 10/100 val_loss 56.86556: 100%|██████████| 6/6 [00:01<00:00,  4.44it/s]\n","Epoch 11/100 loss 48.07263: 100%|██████████| 47/47 [00:19<00:00,  2.41it/s]\n","Epoch 11/100 val_loss 57.63895: 100%|██████████| 6/6 [00:01<00:00,  4.46it/s]\n","Epoch 12/100 loss 47.61518: 100%|██████████| 47/47 [00:21<00:00,  2.22it/s]\n","Epoch 12/100 val_loss 58.25691: 100%|██████████| 6/6 [00:01<00:00,  4.71it/s]\n","Epoch 13/100 loss 47.06949: 100%|██████████| 47/47 [00:19<00:00,  2.42it/s]\n","Epoch 13/100 val_loss 58.20851: 100%|██████████| 6/6 [00:01<00:00,  4.70it/s]\n","Epoch 14/100 loss 46.64078: 100%|██████████| 47/47 [00:21<00:00,  2.23it/s]\n","Epoch 14/100 val_loss 58.96733: 100%|██████████| 6/6 [00:01<00:00,  4.63it/s]\n","Epoch 15/100 loss 45.91171: 100%|██████████| 47/47 [00:19<00:00,  2.39it/s]\n","Epoch 15/100 val_loss 59.51685: 100%|██████████| 6/6 [00:01<00:00,  4.56it/s]\n","Epoch 16/100 loss 45.47250: 100%|██████████| 47/47 [00:21<00:00,  2.23it/s]\n","Epoch 16/100 val_loss 60.65226: 100%|██████████| 6/6 [00:01<00:00,  4.16it/s]\n","Epoch 17/100 loss 45.01544: 100%|██████████| 47/47 [00:19<00:00,  2.38it/s]\n","Epoch 17/100 val_loss 60.83877: 100%|██████████| 6/6 [00:01<00:00,  4.51it/s]\n","Epoch 18/100 loss 44.34209: 100%|██████████| 47/47 [00:21<00:00,  2.20it/s]\n","Epoch 18/100 val_loss 61.24696: 100%|██████████| 6/6 [00:01<00:00,  4.03it/s]\n","Epoch 19/100 loss 43.92072: 100%|██████████| 47/47 [00:19<00:00,  2.40it/s]\n","Epoch 19/100 val_loss 62.40794: 100%|██████████| 6/6 [00:01<00:00,  4.43it/s]\n","Epoch 20/100 loss 43.38631: 100%|██████████| 47/47 [00:20<00:00,  2.25it/s]\n","Epoch 20/100 val_loss 62.86028: 100%|██████████| 6/6 [00:01<00:00,  3.63it/s]\n","Epoch 21/100 loss 43.18735: 100%|██████████| 47/47 [00:19<00:00,  2.36it/s]\n","Epoch 21/100 val_loss 64.32936: 100%|██████████| 6/6 [00:01<00:00,  4.41it/s]\n","Epoch 22/100 loss 42.79762: 100%|██████████| 47/47 [00:21<00:00,  2.20it/s]\n","Epoch 22/100 val_loss 63.82835: 100%|██████████| 6/6 [00:01<00:00,  3.94it/s]\n","Epoch 23/100 loss 42.47670: 100%|██████████| 47/47 [00:20<00:00,  2.33it/s]\n","Epoch 23/100 val_loss 64.54703: 100%|██████████| 6/6 [00:01<00:00,  4.43it/s]\n","Epoch 24/100 loss 41.92519: 100%|██████████| 47/47 [00:21<00:00,  2.16it/s]\n","Epoch 24/100 val_loss 65.42782: 100%|██████████| 6/6 [00:01<00:00,  4.51it/s]\n","Epoch 25/100 loss 41.72673: 100%|██████████| 47/47 [00:19<00:00,  2.39it/s]\n","Epoch 25/100 val_loss 65.67904: 100%|██████████| 6/6 [00:01<00:00,  4.62it/s]\n","Epoch 26/100 loss 41.44283: 100%|██████████| 47/47 [00:21<00:00,  2.22it/s]\n","Epoch 26/100 val_loss 65.98315: 100%|██████████| 6/6 [00:01<00:00,  4.60it/s]\n","Epoch 27/100 loss 40.95409: 100%|██████████| 47/47 [00:19<00:00,  2.40it/s]\n","Epoch 27/100 val_loss 67.46423: 100%|██████████| 6/6 [00:01<00:00,  4.64it/s]\n","Epoch 28/100 loss 40.72329: 100%|██████████| 47/47 [00:20<00:00,  2.25it/s]\n","Epoch 28/100 val_loss 66.86655: 100%|██████████| 6/6 [00:01<00:00,  3.84it/s]\n","Epoch 29/100 loss 40.43064: 100%|██████████| 47/47 [00:19<00:00,  2.39it/s]\n","Epoch 29/100 val_loss 67.30797: 100%|██████████| 6/6 [00:01<00:00,  4.50it/s]\n","Epoch 30/100 loss 40.07644: 100%|██████████| 47/47 [00:20<00:00,  2.27it/s]\n","Epoch 30/100 val_loss 68.54752: 100%|██████████| 6/6 [00:01<00:00,  3.38it/s]\n","Epoch 31/100 loss 40.04097: 100%|██████████| 47/47 [00:19<00:00,  2.41it/s]\n","Epoch 31/100 val_loss 68.24750: 100%|██████████| 6/6 [00:01<00:00,  4.61it/s]\n","Epoch 32/100 loss 39.87515: 100%|██████████| 47/47 [00:20<00:00,  2.30it/s]\n","Epoch 32/100 val_loss 68.35532: 100%|██████████| 6/6 [00:02<00:00,  2.93it/s]\n","Epoch 33/100 loss 39.40576: 100%|██████████| 47/47 [00:19<00:00,  2.41it/s]\n","Epoch 33/100 val_loss 69.29430: 100%|██████████| 6/6 [00:01<00:00,  4.68it/s]\n","Epoch 34/100 loss 39.10408: 100%|██████████| 47/47 [00:20<00:00,  2.34it/s]\n","Epoch 34/100 val_loss 69.13205: 100%|██████████| 6/6 [00:02<00:00,  2.92it/s]\n","Epoch 35/100 loss 38.93125: 100%|██████████| 47/47 [00:20<00:00,  2.35it/s]\n","Epoch 35/100 val_loss 69.97747: 100%|██████████| 6/6 [00:01<00:00,  4.54it/s]\n","Epoch 36/100 loss 38.84900: 100%|██████████| 47/47 [00:19<00:00,  2.36it/s]\n","Epoch 36/100 val_loss 69.98291: 100%|██████████| 6/6 [00:02<00:00,  2.96it/s]\n","Epoch 37/100 loss 38.32615: 100%|██████████| 47/47 [00:20<00:00,  2.33it/s]\n","Epoch 37/100 val_loss 71.03928: 100%|██████████| 6/6 [00:01<00:00,  4.47it/s]\n","Epoch 38/100 loss 38.14255: 100%|██████████| 47/47 [00:19<00:00,  2.37it/s]\n","Epoch 38/100 val_loss 70.77120: 100%|██████████| 6/6 [00:02<00:00,  2.92it/s]\n","Epoch 39/100 loss 37.92258: 100%|██████████| 47/47 [00:20<00:00,  2.33it/s]\n","Epoch 39/100 val_loss 72.12962: 100%|██████████| 6/6 [00:01<00:00,  4.61it/s]\n","Epoch 40/100 loss 37.79421: 100%|██████████| 47/47 [00:19<00:00,  2.39it/s]\n","Epoch 40/100 val_loss 72.21686: 100%|██████████| 6/6 [00:02<00:00,  2.94it/s]\n","Epoch 41/100 loss 37.23483: 100%|██████████| 47/47 [00:20<00:00,  2.30it/s]\n","Epoch 41/100 val_loss 72.86554: 100%|██████████| 6/6 [00:01<00:00,  4.59it/s]\n","Epoch 42/100 loss 37.04875: 100%|██████████| 47/47 [00:19<00:00,  2.43it/s]\n","Epoch 42/100 val_loss 72.99723: 100%|██████████| 6/6 [00:01<00:00,  3.75it/s]\n","Epoch 43/100 loss 37.07287: 100%|██████████| 47/47 [00:21<00:00,  2.23it/s]\n","Epoch 43/100 val_loss 73.77182: 100%|██████████| 6/6 [00:01<00:00,  4.50it/s]\n","Epoch 44/100 loss 36.77230: 100%|██████████| 47/47 [00:19<00:00,  2.39it/s]\n","Epoch 44/100 val_loss 73.29040: 100%|██████████| 6/6 [00:01<00:00,  3.94it/s]\n","Epoch 45/100 loss 36.25938: 100%|██████████| 47/47 [00:20<00:00,  2.25it/s]\n","Epoch 45/100 val_loss 74.22533: 100%|██████████| 6/6 [00:01<00:00,  4.70it/s]\n","Epoch 46/100 loss 36.41801: 100%|██████████| 47/47 [00:19<00:00,  2.40it/s]\n","Epoch 46/100 val_loss 73.17848: 100%|██████████| 6/6 [00:01<00:00,  4.45it/s]\n","Epoch 47/100 loss 36.28020: 100%|██████████| 47/47 [00:21<00:00,  2.23it/s]\n","Epoch 47/100 val_loss 74.29923: 100%|██████████| 6/6 [00:01<00:00,  4.66it/s]\n","Epoch 48/100 loss 35.82878: 100%|██████████| 47/47 [00:19<00:00,  2.39it/s]\n","Epoch 48/100 val_loss 74.76143: 100%|██████████| 6/6 [00:01<00:00,  4.47it/s]\n","Epoch 49/100 loss 35.43735: 100%|██████████| 47/47 [00:21<00:00,  2.20it/s]\n","Epoch 49/100 val_loss 75.67918: 100%|██████████| 6/6 [00:01<00:00,  4.56it/s]\n","Epoch 50/100 loss 35.44599: 100%|██████████| 47/47 [00:19<00:00,  2.39it/s]\n","Epoch 50/100 val_loss 75.32007: 100%|██████████| 6/6 [00:01<00:00,  4.60it/s]\n","Epoch 51/100 loss 35.08536: 100%|██████████| 47/47 [00:21<00:00,  2.22it/s]\n","Epoch 51/100 val_loss 75.54402: 100%|██████████| 6/6 [00:01<00:00,  4.53it/s]\n","Epoch 52/100 loss 34.89108: 100%|██████████| 47/47 [00:19<00:00,  2.41it/s]\n","Epoch 52/100 val_loss 76.33123: 100%|██████████| 6/6 [00:01<00:00,  4.55it/s]\n","Epoch 53/100 loss 34.80078: 100%|██████████| 47/47 [00:21<00:00,  2.21it/s]\n","Epoch 53/100 val_loss 76.66058: 100%|██████████| 6/6 [00:01<00:00,  4.52it/s]\n","Epoch 54/100 loss 34.45887: 100%|██████████| 47/47 [00:19<00:00,  2.40it/s]\n","Epoch 54/100 val_loss 76.72695: 100%|██████████| 6/6 [00:01<00:00,  4.65it/s]\n","Epoch 55/100 loss 34.22327: 100%|██████████| 47/47 [00:21<00:00,  2.22it/s]\n","Epoch 55/100 val_loss 77.19252: 100%|██████████| 6/6 [00:01<00:00,  4.48it/s]\n","Epoch 56/100 loss 33.99636: 100%|██████████| 47/47 [00:19<00:00,  2.40it/s]\n","Epoch 56/100 val_loss 76.87700: 100%|██████████| 6/6 [00:01<00:00,  4.57it/s]\n","Epoch 57/100 loss 33.68745: 100%|██████████| 47/47 [00:21<00:00,  2.23it/s]\n","Epoch 57/100 val_loss 78.65423: 100%|██████████| 6/6 [00:01<00:00,  4.39it/s]\n","Epoch 58/100 loss 33.74238: 100%|██████████| 47/47 [00:19<00:00,  2.41it/s]\n","Epoch 58/100 val_loss 78.49218: 100%|██████████| 6/6 [00:01<00:00,  4.60it/s]\n","Epoch 59/100 loss 33.17102: 100%|██████████| 47/47 [00:20<00:00,  2.25it/s]\n","Epoch 59/100 val_loss 78.96305: 100%|██████████| 6/6 [00:01<00:00,  3.70it/s]\n","Epoch 60/100 loss 32.80316: 100%|██████████| 47/47 [00:19<00:00,  2.40it/s]\n","Epoch 60/100 val_loss 79.23534: 100%|██████████| 6/6 [00:01<00:00,  4.57it/s]\n","Epoch 61/100 loss 33.07843: 100%|██████████| 47/47 [00:20<00:00,  2.26it/s]\n","Epoch 61/100 val_loss 79.14654: 100%|██████████| 6/6 [00:01<00:00,  3.34it/s]\n","Epoch 62/100 loss 32.89981: 100%|██████████| 47/47 [00:19<00:00,  2.38it/s]\n","Epoch 62/100 val_loss 79.27990: 100%|██████████| 6/6 [00:01<00:00,  4.67it/s]\n","Epoch 63/100 loss 32.38859: 100%|██████████| 47/47 [00:20<00:00,  2.30it/s]\n","Epoch 63/100 val_loss 80.02166: 100%|██████████| 6/6 [00:02<00:00,  3.00it/s]\n","Epoch 64/100 loss 32.14147: 100%|██████████| 47/47 [00:19<00:00,  2.41it/s]\n","Epoch 64/100 val_loss 80.59349: 100%|██████████| 6/6 [00:01<00:00,  4.56it/s]\n","Epoch 65/100 loss 32.16228: 100%|██████████| 47/47 [00:20<00:00,  2.32it/s]\n","Epoch 65/100 val_loss 80.78523: 100%|██████████| 6/6 [00:02<00:00,  2.87it/s]\n","Epoch 66/100 loss 31.89924: 100%|██████████| 47/47 [00:19<00:00,  2.36it/s]\n","Epoch 66/100 val_loss 80.28459: 100%|██████████| 6/6 [00:01<00:00,  4.55it/s]\n","Epoch 67/100 loss 31.57443: 100%|██████████| 47/47 [00:20<00:00,  2.33it/s]\n","Epoch 67/100 val_loss 81.58697: 100%|██████████| 6/6 [00:02<00:00,  2.91it/s]\n","Epoch 68/100 loss 31.20531: 100%|██████████| 47/47 [00:20<00:00,  2.34it/s]\n","Epoch 68/100 val_loss 81.81775: 100%|██████████| 6/6 [00:01<00:00,  4.49it/s]\n","Epoch 69/100 loss 31.01119: 100%|██████████| 47/47 [00:19<00:00,  2.38it/s]\n","Epoch 69/100 val_loss 81.77797: 100%|██████████| 6/6 [00:02<00:00,  2.94it/s]\n","Epoch 70/100 loss 30.88769: 100%|██████████| 47/47 [00:20<00:00,  2.33it/s]\n","Epoch 70/100 val_loss 81.78506: 100%|██████████| 6/6 [00:01<00:00,  4.62it/s]\n","Epoch 71/100 loss 30.69705: 100%|██████████| 47/47 [00:19<00:00,  2.37it/s]\n","Epoch 71/100 val_loss 81.83088: 100%|██████████| 6/6 [00:02<00:00,  2.86it/s]\n","Epoch 72/100 loss 30.42833: 100%|██████████| 47/47 [00:20<00:00,  2.30it/s]\n","Epoch 72/100 val_loss 82.60609: 100%|██████████| 6/6 [00:01<00:00,  4.53it/s]\n","Epoch 73/100 loss 30.35455: 100%|██████████| 47/47 [00:19<00:00,  2.39it/s]\n","Epoch 73/100 val_loss 83.27768: 100%|██████████| 6/6 [00:01<00:00,  3.11it/s]\n","Epoch 74/100 loss 30.60653: 100%|██████████| 47/47 [00:20<00:00,  2.28it/s]\n","Epoch 74/100 val_loss 82.85340: 100%|██████████| 6/6 [00:01<00:00,  4.63it/s]\n","Epoch 75/100 loss 30.00720: 100%|██████████| 47/47 [00:19<00:00,  2.39it/s]\n","Epoch 75/100 val_loss 83.20813: 100%|██████████| 6/6 [00:01<00:00,  3.47it/s]\n","Epoch 76/100 loss 29.72723: 100%|██████████| 47/47 [00:21<00:00,  2.23it/s]\n","Epoch 76/100 val_loss 83.60924: 100%|██████████| 6/6 [00:01<00:00,  4.65it/s]\n","Epoch 77/100 loss 29.43925: 100%|██████████| 47/47 [00:19<00:00,  2.39it/s]\n","Epoch 77/100 val_loss 83.70490: 100%|██████████| 6/6 [00:01<00:00,  3.64it/s]\n","Epoch 78/100 loss 29.14543: 100%|██████████| 47/47 [00:20<00:00,  2.24it/s]\n","Epoch 78/100 val_loss 84.79255: 100%|██████████| 6/6 [00:01<00:00,  4.48it/s]\n","Epoch 79/100 loss 28.83440: 100%|██████████| 47/47 [00:19<00:00,  2.38it/s]\n","Epoch 79/100 val_loss 85.20164: 100%|██████████| 6/6 [00:01<00:00,  3.73it/s]\n","Epoch 80/100 loss 28.72168: 100%|██████████| 47/47 [00:21<00:00,  2.23it/s]\n","Epoch 80/100 val_loss 85.03103: 100%|██████████| 6/6 [00:01<00:00,  4.63it/s]\n","Epoch 81/100 loss 28.69496: 100%|██████████| 47/47 [00:19<00:00,  2.37it/s]\n","Epoch 81/100 val_loss 85.12180: 100%|██████████| 6/6 [00:01<00:00,  3.66it/s]\n","Epoch 82/100 loss 28.51365: 100%|██████████| 47/47 [00:21<00:00,  2.21it/s]\n","Epoch 82/100 val_loss 85.48032: 100%|██████████| 6/6 [00:01<00:00,  4.40it/s]\n","Epoch 83/100 loss 28.24883: 100%|██████████| 47/47 [00:19<00:00,  2.37it/s]\n","Epoch 83/100 val_loss 85.74735: 100%|██████████| 6/6 [00:01<00:00,  3.47it/s]\n","Epoch 84/100 loss 28.11935: 100%|██████████| 47/47 [00:20<00:00,  2.24it/s]\n","Epoch 84/100 val_loss 85.97812: 100%|██████████| 6/6 [00:01<00:00,  4.37it/s]\n","Epoch 85/100 loss 28.03936: 100%|██████████| 47/47 [00:20<00:00,  2.30it/s]\n","Epoch 85/100 val_loss 85.87501: 100%|██████████| 6/6 [00:02<00:00,  2.92it/s]\n","Epoch 86/100 loss 27.85382: 100%|██████████| 47/47 [00:20<00:00,  2.30it/s]\n","Epoch 86/100 val_loss 86.98445: 100%|██████████| 6/6 [00:01<00:00,  4.55it/s]\n","Epoch 87/100 loss 27.65521: 100%|██████████| 47/47 [00:19<00:00,  2.41it/s]\n","Epoch 87/100 val_loss 86.01956: 100%|██████████| 6/6 [00:01<00:00,  3.59it/s]\n","Epoch 88/100 loss 27.23835: 100%|██████████| 47/47 [00:20<00:00,  2.26it/s]\n","Epoch 88/100 val_loss 87.22818: 100%|██████████| 6/6 [00:01<00:00,  4.54it/s]\n","Epoch 89/100 loss 26.76414: 100%|██████████| 47/47 [00:19<00:00,  2.40it/s]\n","Epoch 89/100 val_loss 88.25531: 100%|██████████| 6/6 [00:01<00:00,  4.00it/s]\n","Epoch 90/100 loss 26.46016: 100%|██████████| 47/47 [00:21<00:00,  2.23it/s]\n","Epoch 90/100 val_loss 88.20157: 100%|██████████| 6/6 [00:01<00:00,  4.52it/s]\n","Epoch 91/100 loss 26.20030: 100%|██████████| 47/47 [00:19<00:00,  2.41it/s]\n","Epoch 91/100 val_loss 88.38305: 100%|██████████| 6/6 [00:01<00:00,  4.74it/s]\n","Epoch 92/100 loss 26.23731: 100%|██████████| 47/47 [00:21<00:00,  2.21it/s]\n","Epoch 92/100 val_loss 88.98613: 100%|██████████| 6/6 [00:01<00:00,  4.42it/s]\n","Epoch 93/100 loss 26.08607: 100%|██████████| 47/47 [00:20<00:00,  2.25it/s]\n","Epoch 93/100 val_loss 88.57703: 100%|██████████| 6/6 [00:01<00:00,  3.35it/s]\n","Epoch 94/100 loss 25.78879: 100%|██████████| 47/47 [00:20<00:00,  2.24it/s]\n","Epoch 94/100 val_loss 89.10032: 100%|██████████| 6/6 [00:01<00:00,  4.44it/s]\n","Epoch 95/100 loss 25.59507: 100%|██████████| 47/47 [00:19<00:00,  2.36it/s]\n","Epoch 95/100 val_loss 88.99345: 100%|██████████| 6/6 [00:01<00:00,  3.12it/s]\n","Epoch 96/100 loss 25.20279: 100%|██████████| 47/47 [00:20<00:00,  2.24it/s]\n","Epoch 96/100 val_loss 89.65474: 100%|██████████| 6/6 [00:01<00:00,  4.47it/s]\n","Epoch 97/100 loss 24.92227: 100%|██████████| 47/47 [00:19<00:00,  2.38it/s]\n","Epoch 97/100 val_loss 90.19644: 100%|██████████| 6/6 [00:02<00:00,  2.94it/s]\n","Epoch 98/100 loss 24.72896: 100%|██████████| 47/47 [00:20<00:00,  2.25it/s]\n","Epoch 98/100 val_loss 90.50069: 100%|██████████| 6/6 [00:01<00:00,  4.38it/s]\n","Epoch 99/100 loss 24.68739: 100%|██████████| 47/47 [00:21<00:00,  2.21it/s]\n","Epoch 99/100 val_loss 90.82610: 100%|██████████| 6/6 [00:02<00:00,  2.81it/s]\n","Epoch 100/100 loss 24.45155: 100%|██████████| 47/47 [00:20<00:00,  2.32it/s]\n","Epoch 100/100 val_loss 90.55884: 100%|██████████| 6/6 [00:01<00:00,  4.52it/s]\n"]}],"source":["fit(encoder, decoder, dataloader, epochs=100)"]},{"cell_type":"markdown","metadata":{"id":"81pQZ8FODhIH"},"source":["## Generando traducciones"]},{"cell_type":"markdown","metadata":{"id":"zpf0z3bbDhIH"},"source":["Una vez tenemos nuestro modelo entrenado, podemos utilizarlo para traducir frases del inglés al castellano de la siguiente manera."]},{"cell_type":"code","execution_count":33,"metadata":{"id":"zcFY7vzDDhIH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687527138210,"user_tz":240,"elapsed":343,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}},"outputId":"db89ae5d-6a62-4984-b02e-15be8ef87eec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['and',\n","  'people',\n","  'showed',\n","  'up',\n","  '.',\n","  'EOS',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD'],\n"," ['so',\n","  'many',\n","  'people',\n","  'are',\n","  'out',\n","  'of',\n","  'work',\n","  '.',\n","  'EOS',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD',\n","  'PAD'])"]},"metadata":{},"execution_count":33}],"source":["input_sentence, output_sentence = dataset['test'][0]\n","question_lang.questionFromIds(input_sentence.tolist()), answer_lang.questionFromIds(output_sentence.tolist())"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"RzxhNLU8DhIH","executionInfo":{"status":"ok","timestamp":1687527143665,"user_tz":240,"elapsed":328,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":["def predict(input_sentence):\n","    # obtenemos el último estado oculto del encoder\n","    encoder_outputs, hidden = encoder(input_sentence.unsqueeze(0))\n","    # calculamos las salidas del decoder de manera recurrente\n","    decoder_input = torch.tensor([[answer_lang.word2id['SOS']]], device=device)\n","    # iteramos hasta que el decoder nos de el token <eos>\n","    outputs = []\n","    decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)\n","    i = 0\n","    while True:\n","        output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n","        decoder_attentions[i] = attn_weights.data\n","        i += 1\n","        decoder_input = torch.argmax(output, axis=1).view(1, 1)\n","        outputs.append(decoder_input.cpu().item())\n","        if decoder_input.item() == answer_lang.word2id['EOS']:\n","            break\n","    return answer_lang.questionFromIds(outputs), decoder_attentions"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"nJWDsiGsDhII","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687527149080,"user_tz":240,"elapsed":316,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}},"outputId":"634c893f-810a-47a8-9ff8-9b3a01373fbd"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-27-c73859c09972>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n"]},{"output_type":"execute_result","data":{"text/plain":["['what', 'are', 'that', '?', 'EOS']"]},"metadata":{},"execution_count":35}],"source":["output_words, attn = predict(input_sentence)\n","output_words"]},{"cell_type":"markdown","metadata":{"id":"FVk45xViDhII"},"source":["## Visualización de atención"]},{"cell_type":"markdown","metadata":{"id":"ZIwB1jkSDhII"},"source":["Una de las ventajas que nos da la capa de atención es que nos permite visualizar en qué partes de los inputs se fija el modelo para generar cada una de las palabras en el output, dando un grado de explicabilidad a nuestro modelo (una propiedad siempre deseada en nuestro modelos de `Machine Learning`)."]},{"cell_type":"code","execution_count":36,"metadata":{"id":"ZnOX1xXEDhII","executionInfo":{"status":"ok","timestamp":1687527156764,"user_tz":240,"elapsed":422,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","def showAttention(input_sentence, output_words, attentions):\n","    lim1, lim2 = input_sentence.index('EOS')+1, output_words.index('EOS')+1\n","    fig = plt.figure(dpi=100)\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(attentions[:lim2, :lim1].numpy(), cmap='bone')\n","    fig.colorbar(cax)\n","    # Set up axes\n","    ax.set_xticklabels([' '] + input_sentence[:lim1], rotation=90)\n","    ax.set_yticklabels([' '] + output_words)\n","    # Show label at every tick\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","    plt.show()"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"vchBo16ODhII","colab":{"base_uri":"https://localhost:8080/","height":518},"executionInfo":{"status":"ok","timestamp":1687527162987,"user_tz":240,"elapsed":906,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}},"outputId":"39610307-d697-4df6-b4ef-96df84797954"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-36-c3618fc79f44>:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n","  ax.set_xticklabels([' '] + input_sentence[:lim1], rotation=90)\n","<ipython-input-36-c3618fc79f44>:12: UserWarning: FixedFormatter should only be used together with FixedLocator\n","  ax.set_yticklabels([' '] + output_words)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["showAttention(question_lang.questionFromIds(input_sentence.tolist()), output_words, attn)"]},{"cell_type":"markdown","metadata":{"id":"X07C6dWtFaiI"},"source":["TRANSFER LEAARNING\n","con el transfomer RoBERTa"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"cn2FyTrkF_CO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687527184233,"user_tz":240,"elapsed":15234,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}},"outputId":"6a0fb1cf-fbee-4930-a2a0-b93df493ada8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"cCjtyL3cXuUu","executionInfo":{"status":"ok","timestamp":1687527188692,"user_tz":240,"elapsed":2597,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["3d0c0dc597b04bf58a8e0c7f42d3c5e9","1ad9d691f67c4a8cb1448858de18e01a","67863a79096243b49fa857d62bfaacea","ed9cc11bcbe241d58935b3d68df84276","6e70172219c84e95ae21b3f7863f45b0","22264ddd1a9e483190e376d547c843f7","90653f4a15b1444e9008c6771046b5ff","095141f9353442b9a4d498f3c5acd01e","c0b1130d54d044e5a587bb0e9d5ca13e","0c3af6c1392340f58efe4d8f9e2456ae","3f24ffe215714b4cba7bd40851483a70","64d4287b1d9c455fa2e71c1f78e27f7c","27ed51e5856941ca86f3ab5d1baae18d","2dc1c2513ba54f2ea73205e9ab550ba6","1a569899935c4436a20d16d2accd57f3","60770fd7e45b41dda06c834f83592aad","d3193fbeb758443db403593edf879297","a0795c15a76f4b4bbee7e44f721a7b14","14982dbb07c847d99dca3a0a4be061c1","94d8beadeda24929a19a48c0be7f010b","98b27338fc604f26bad8781fc944e85e","c2a291b3f42541bcbcff6504baaab5b0","77f31a72776742c19bb81818c8e36dd4","b6ea4cd37a62442c9286a8627f7004f6","dd97afb6d89d464b93b8fc62a7b01c32","f72253a86a6e488386979b372b2d5e5f","c9d205685c2c466591ab3824c54ba5c4","c936a8815a414e5cb9d6813e2a577215","b8abf5f3af8b4e97b7b3039f4ea9e6c8","bf2c28e420394d29bc98289015a0e38b","9173a2762a6641d19afa388f08bd3777","c87a3b7620224ce9b98c90b85b8cf2ab","50224ecd71e14d4187f3537623d95f44"]},"outputId":"540ff1e4-2b58-4958-ce9e-fec7641456b1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d0c0dc597b04bf58a8e0c7f42d3c5e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64d4287b1d9c455fa2e71c1f78e27f7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77f31a72776742c19bb81818c8e36dd4"}},"metadata":{}}],"source":["import torch\n","from transformers import RobertaModel, RobertaTokenizer\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"JSlcP9rvNJzl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687527191799,"user_tz":240,"elapsed":740,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}},"outputId":"3fd645f9-afa1-4ece-ffef-296a7f85394e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tenemos 3725 pares de frases\n","Tenemos 3725 pares de frases con longitud menor de 512\n"]},{"output_type":"execute_result","data":{"text/plain":["['i don t think so . after i finish i ll have enough money to go to college .',\n"," 'that s not a bad idea .']"]},"metadata":{},"execution_count":40}],"source":["import random\n","max_length = tokenizer.model_max_length\n","def filterPairs(pairs, filters, lang=0):\n","    return pairs\n","def trimPairs2(pairs):\n","    return [p for p in pairs if len(p[0].split(' ')) < max_length and len(p[1].split(' ')) < max_length]\n","def prepareData(file, filters=None, reverse=False):\n","    pairs = read_file(file, reverse)\n","    print(f\"Tenemos {len(pairs)} pares de frases\")\n","\n","    pairs = trimPairs2(pairs)\n","    print(f\"Tenemos {len(pairs)} pares de frases con longitud menor de {max_length}\")\n","\n","    # Reverse pairs, make Lang instances\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","\n","    return pairs\n","\n","pairs2 = prepareData('/content/drive/MyDrive/SIS421/EXAMENFINAL/dialogos.txt')\n","\n","random.choice(pairs2)"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"QWsMycyhGPm1","executionInfo":{"status":"ok","timestamp":1687528032969,"user_tz":240,"elapsed":302,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":["max_length = 40\n","\n","def collate_fn(batch):\n","    questions, answers = zip(*batch)\n","\n","    # Tokenizar y aplicar relleno a las preguntas\n","    question_inputs = tokenizer(questions, truncation=True, padding='max_length', max_length=max_length, return_tensors=\"pt\")\n","    question_input_ids = question_inputs['input_ids']\n","    question_attention_mask = question_inputs['attention_mask']\n","\n","    # Tokenizar y aplicar relleno a las respuestas\n","    answer_inputs = tokenizer(answers, truncation=True, padding='max_length', max_length=max_length, return_tensors=\"pt\")\n","    answer_input_ids = answer_inputs['input_ids']\n","    answer_attention_mask = answer_inputs['attention_mask']\n","\n","    return (question_input_ids, question_attention_mask), (answer_input_ids, answer_attention_mask)\n","class DialogDataset(torch.utils.data.Dataset):\n","    def __init__(self, pairs):\n","        self.pairs = pairs\n","\n","    def __len__(self):\n","        return len(self.pairs)\n","\n","    def __getitem__(self, index):\n","        question = self.pairs[index][0]\n","        answer = self.pairs[index][1]\n","        return question, answer\n","\n","train_size = len(pairs2) * 70 // 100\n","train = pairs2[:train_size]\n","test = pairs2[train_size:]"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"gfh5dt0iGPfQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687528082086,"user_tz":240,"elapsed":1036,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}},"outputId":"90e17316-bc91-4fee-9796-5ac82b17f2cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["2607 1118\n","torch.Size([256, 40])\n","torch.Size([256, 40])\n","torch.Size([256, 40])\n","torch.Size([256, 40])\n"]}],"source":["dataset = {\n","    'train': DialogDataset(train),\n","    'test': DialogDataset(test)\n","}\n","print(len(dataset['train']), len(dataset['test']))\n","dataloader = {\n","    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=256, shuffle=True, collate_fn=collate_fn),\n","    'test': torch.utils.data.DataLoader(dataset['test'], batch_size=256, shuffle=False, collate_fn=collate_fn)\n","}\n","\n","inputs, outputs = next(iter(dataloader['train']))\n","question_input_ids, question_attention_mask = inputs\n","answer_input_ids, answer_attention_mask = outputs\n","print(question_input_ids.shape)\n","print(question_attention_mask.shape)\n","print(answer_input_ids.shape)\n","print(answer_attention_mask.shape)"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"6kEwBE4NGPb1","executionInfo":{"status":"ok","timestamp":1687528093127,"user_tz":240,"elapsed":323,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":50,"metadata":{"id":"6tiAJmJBv7YS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687528097897,"user_tz":240,"elapsed":2130,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}},"outputId":"f7831332-efd7-453d-c44a-3732f14c753f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["RobertaModel(\n","  (embeddings): RobertaEmbeddings(\n","    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","    (position_embeddings): Embedding(514, 768, padding_idx=1)\n","    (token_type_embeddings): Embedding(1, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): RobertaEncoder(\n","    (layer): ModuleList(\n","      (0-11): 12 x RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): RobertaPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{},"execution_count":50}],"source":["# Obtener la lista de módulos del modelo\n","model = RobertaModel.from_pretrained('roberta-base')\n","model"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"qNH_NGNSGPZS","executionInfo":{"status":"ok","timestamp":1687528137731,"user_tz":240,"elapsed":2,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":["\n","import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class Encoder(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.roberta = RobertaModel.from_pretrained('roberta-base')\n","\n","        # Congelar los parámetros del modelo preentrenado\n","        for name, param in self.roberta.named_parameters():\n","            if name.startswith('roberta'):\n","                param.requires_grad = False\n","\n","    def forward(self, input_ids, attention_mask):\n","        with torch.no_grad():\n","            outputs = self.roberta(input_ids, attention_mask=attention_mask)\n","            encoded_layers = outputs.last_hidden_state\n","            hidden = outputs.pooler_output\n","            #hidden = outputs.hidden_states[-1]\n","        return encoded_layers, hidden"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"VJ7F2tG-X_dZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687528201434,"user_tz":240,"elapsed":41363,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}},"outputId":"89ad3dec-74e7-4abe-810d-2c825f6ce397"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([256, 40, 768])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([256, 768])"]},"metadata":{},"execution_count":52}],"source":["encoder = Encoder()\n","encoder_outputs, encoder_hidden = encoder(question_input_ids, question_attention_mask)\n","\n","# [batch size, seq len, hidden size]\n","print(encoder_outputs.shape)\n","\n","# [num layers, batch size, hidden size]\n","encoder_hidden.shape\n"]},{"cell_type":"code","source":["class DialogDecoder(torch.nn.Module):\n","    def __init__(self, input_size, hidden_size, max_length):\n","        super().__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.max_length = max_length\n","\n","        self.embedding = torch.nn.Embedding(input_size, hidden_size)\n","        self.gru = torch.nn.GRU(hidden_size, hidden_size)\n","        self.attn = torch.nn.Linear(hidden_size + hidden_size, max_length)\n","        self.attn_combine = torch.nn.Linear(hidden_size + hidden_size, hidden_size)\n","        self.out = torch.nn.Linear(hidden_size, input_size)\n","\n","    def forward(self, input_ids, attention_mask, encoder_hidden_states, encoder_outputs):\n","        batch_size, seq_length = input_ids.size()\n","        #print(attention_mask.shape)\n","\n","        embedded = self.embedding(input_ids)\n","        #print(embedded.shape)\n","        embedded1 = embedded * attention_mask.unsqueeze(-1)\n","        #print(embedded1.shape) # Apply attention mask to embeddings\n","        embedded = embedded1.permute(1, 0, 2)\n","        #print(embedded.shape)  # (seq_length, batch_size, hidden_size)\n","\n","        # Aplicamos la capa GRU\n","        _, hidden = self.gru(embedded)\n","        #print(hidden.shape)\n","\n","        # Obtenemos el último estado oculto de la GRU\n","        hidden = hidden[-1].unsqueeze(0)  # (1, batch_size, hidden_size)\n","        #print(hidden.shape)\n","\n","        # Ajustamos las dimensiones para el cálculo de la atención\n","        hidden = hidden.permute(1, 0, 2)  # (batch_size, 1, hidden_size)\n","        #print(hidden.shape)\n","        hidden = hidden.expand(-1, seq_length, -1)  # (batch_size, seq_length, hidden_size)\n","        #print(hidden.shape)\n","\n","        # Calculamos los pesos de atención\n","        attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded1, hidden), dim=2)), dim=2)\n","        #print(\"el\",attn_weights.shape)\n","        #a=encoder_outputs.permute(1, 2, 0)\n","        #print(a.shape)\n","\n","        # Aplicamos la atención a los estados ocultos del codificador\n","        attn_applied = torch.bmm(attn_weights, encoder_outputs)\n","        #print(attn_applied.shape)\n","\n","        # Concatenamos los embeddings con la atención aplicada\n","        output = torch.cat((embedded1, attn_applied), dim=2)\n","        output = self.attn_combine(output)\n","\n","        # Aplicamos la capa lineal y la función de activación\n","        output = torch.relu(output)\n","\n","        # Aplicamos la capa lineal de salida\n","        output = self.out(output.squeeze(0))\n","\n","        return output, hidden, attn_weights\n"],"metadata":{"id":"4W68wFRNIBFI","executionInfo":{"status":"ok","timestamp":1687528274270,"user_tz":240,"elapsed":329,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["decoder = DialogDecoder(input_size=tokenizer.vocab_size, hidden_size=768, max_length=40)\n","decoder_output, decoder_hidden, attention_weights = decoder(answer_input_ids, answer_attention_mask, encoder_hidden, encoder_outputs)\n","\n","# [batch size, seq len, vocab size]\n","print(decoder_output.shape)\n","# [batch size, seq len, max_length]\n","print(attention_weights.shape)\n","print(decoder_hidden.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N71_dhnQIf_L","executionInfo":{"status":"ok","timestamp":1687528298505,"user_tz":240,"elapsed":17878,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}},"outputId":"bb75f554-5305-4f25-80bd-85ac9334807a"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([256, 40, 50265])\n","torch.Size([256, 40, 40])\n","torch.Size([256, 40, 768])\n"]}]},{"cell_type":"code","source":["from tqdm import tqdm\n","import numpy as np\n","torch.autograd.set_detect_anomaly(True)\n","def fit(encoder, decoder, dataloader, epochs=10):\n","    encoder.to(device)\n","    decoder.to(device)\n","    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n","    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n","    criterion = torch.nn.CrossEntropyLoss()\n","\n","    for epoch in range(1, epochs+1):\n","        encoder.train()\n","        decoder.train()\n","        train_loss = []\n","        bar = tqdm(dataloader['train'])\n","\n","        for batch in bar:\n","            batch_inputs, batch_outputs = batch\n","            question_input_ids, question_attention_mask = batch_inputs\n","            answer_input_ids, answer_attention_mask = batch_outputs\n","\n","            bs = question_input_ids.shape[0]\n","            loss = 0\n","\n","            encoder_optimizer.zero_grad()\n","            decoder_optimizer.zero_grad()\n","\n","            # Obtenemos el último estado oculto y las salidas del encoder\n","            encoder_outputs, encoder_hidden = encoder(question_input_ids.to(device), question_attention_mask.to(device))\n","            #print(\"los\",encoder_outputs.shape)\n","\n","            # Calculamos las salidas del decoder de manera recurrente\n","            max_length = 40  # Definir la longitud máxima deseada\n","            decoder_input = torch.full((bs, max_length), tokenizer.pad_token_id, device=device)\n","            #decoder_input = torch.tensor([[tokenizer.pad_token_id] for _ in range(bs)], device=device)\n","            #print(\"bla bla\",decoder_input.shape)\n","            decoder_hidden = encoder_hidden  # Usamos el estado oculto del encoder como estado oculto inicial del decoder\n","            decoder_input = decoder_input.detach()\n","            for i in range(answer_input_ids.shape[1]):\n","                decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, answer_attention_mask, decoder_hidden, encoder_outputs)\n","                output = decoder_output[:, 0, :]\n","                #print(outputs.shape)\n","                loss += criterion(output, answer_input_ids[:, i])\n","\n","                # El siguiente input será la palabra predicha\n","                #decoder_input = torch.argmax(output, axis=1).unsqueeze(1)\n","                #decoder_input[:, i] = torch.argmax(output, axis=1)\n","                decoder_input[:, i] = torch.argmax(output, axis=1).detach()\n","                #print(\"mis\",decoder_input.shape)\n","\n","            # Optimización\n","            loss.backward()\n","            encoder_optimizer.step()\n","            decoder_optimizer.step()\n","            train_loss.append(loss.item())\n","            bar.set_description(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f}\")\n","\n","        val_loss = []\n","        encoder.eval()\n","        decoder.eval()\n","\n","        with torch.no_grad():\n","            bar = tqdm(dataloader['test'])\n","\n","            for batch in bar:\n","                inputs, outputs = batch\n","                question_input_ids, question_attention_mask = inputs\n","                answer_input_ids, answer_attention_mask = outputs\n","\n","                bs = question_input_ids.shape[0]\n","                loss = 0\n","\n","                # Obtenemos el último estado oculto y las salidas del encoder\n","                encoder_outputs, encoder_hidden = encoder(question_input_ids.to(device), question_attention_mask.to(device))\n","\n","                # Calculamos las salidas del decoder de manera recurrente\n","                decoder_input = torch.full((bs, max_length), tokenizer.pad_token_id, device=device)\n","                decoder_hidden = encoder_hidden  # Usamos el estado oculto del encoder como estado oculto inicial del decoder\n","                decoder_input = decoder_input.detach()\n","                for i in range(answer_input_ids.shape[1]):\n","                    decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, answer_attention_mask, decoder_hidden, encoder_outputs)\n","                    output = decoder_output[:, 0, :]\n","                    loss += criterion(output, answer_input_ids[:, i])\n","\n","                    # El siguiente input será la palabra predicha\n","                    #decoder_input[:, i] = torch.argmax(output, axis=1)\n","                    decoder_input[:, i] = torch.argmax(output, axis=1).detach()\n","\n","                val_loss.append(loss.item())\n","                bar.set_description(f\"Epoch {epoch}/{epochs} val_loss {np.mean(val_loss):.5f}\")\n"],"metadata":{"id":"vepdRzlOytQO","executionInfo":{"status":"ok","timestamp":1687528333082,"user_tz":240,"elapsed":288,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["fit(encoder, decoder, dataloader, epochs=3)"],"metadata":{"id":"BSXNnSFy0Mmx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cbac8eb4-d9f6-4ed1-ef9e-7fb2b3828a40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/11 [00:00<?, ?it/s]"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HU-ypf1KGPS_","executionInfo":{"status":"aborted","timestamp":1687524728953,"user_tz":240,"elapsed":11,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":["def predict(encoder, decoder, question_input_ids, question_attention_mask, max_length=40):\n","    encoder.to(device)\n","    decoder.to(device)\n","    encoder.eval()\n","    decoder.eval()\n","\n","    with torch.no_grad():\n","        bs = question_input_ids.shape[0]\n","        decoder_input = torch.full((bs, max_length), tokenizer.pad_token_id, device=device)\n","        encoder_outputs, encoder_hidden = encoder(question_input_ids.to(device), question_attention_mask.to(device))\n","        decoder_hidden = encoder_hidden\n","\n","        outputs = []\n","\n","        for i in range(max_length):\n","            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n","            output = decoder_output[:, 0, :]\n","            predicted_ids = torch.argmax(output, axis=1)\n","            decoder_input[:, i] = predicted_ids\n","            outputs.append(predicted_ids.unsqueeze(1))\n","\n","        outputs = torch.cat(outputs, dim=1)\n","\n","    return outputs\n"]},{"cell_type":"code","source":["question_input_ids = ...  # Datos de entrada de preguntas\n","question_attention_mask = ...  # Máscaras de atención para los datos de entrada de preguntas\n","\n","predicted_output = predict(encoder, decoder, question_input_ids, question_attention_mask)"],"metadata":{"id":"ohwvcAY91pHy","executionInfo":{"status":"aborted","timestamp":1687524728953,"user_tz":240,"elapsed":11,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jqoVccIeX7tX","executionInfo":{"status":"aborted","timestamp":1687524728954,"user_tz":240,"elapsed":12,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":["batch = next(iter(dataloader))\n","\n","# Obtener el valor específico de question_input_ids y question_attention_mask\n","question_input_ids = batch[0][0]  # Acceder al primer elemento del primer lote\n","question_attention_mask = batch[1][0]  # Acceder al primer elemento del segundo lote\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HYwTtVnX17a","executionInfo":{"status":"aborted","timestamp":1687524728954,"user_tz":240,"elapsed":12,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nKel_jstGPAr","executionInfo":{"status":"aborted","timestamp":1687524728954,"user_tz":240,"elapsed":12,"user":{"displayName":"Luis Gustavo Ortiz","userId":"13432368426195691699"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"uP0Bx95ZDhII"},"source":["## Resumen"]},{"cell_type":"markdown","metadata":{"id":"Ozvpo0sfDhII"},"source":["En este post hemos visto como introducir mecanismos de atención en nuestra arquitectura `encoder-decoder`, los cuales permiten a nuestra red neuronal focalizarse en partes concretas de los *inputs* a la hora de generar los *outputs*. Esta nueva capa no solo puede mejorar nuestros modelos sino que además también es interpretable, dándonos una idea del razonamiento detrás de las predicciones de nuestro modelo. Las redes neuronales con mejores prestaciones a día de hoy en tareas de `NLP`, los `transformers`, están basados enteramente en este tipo de capas de atención."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"233.594px"},"toc_section_display":true,"toc_window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"3d0c0dc597b04bf58a8e0c7f42d3c5e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ad9d691f67c4a8cb1448858de18e01a","IPY_MODEL_67863a79096243b49fa857d62bfaacea","IPY_MODEL_ed9cc11bcbe241d58935b3d68df84276"],"layout":"IPY_MODEL_6e70172219c84e95ae21b3f7863f45b0"}},"1ad9d691f67c4a8cb1448858de18e01a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22264ddd1a9e483190e376d547c843f7","placeholder":"​","style":"IPY_MODEL_90653f4a15b1444e9008c6771046b5ff","value":"Downloading (…)olve/main/vocab.json: "}},"67863a79096243b49fa857d62bfaacea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_095141f9353442b9a4d498f3c5acd01e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0b1130d54d044e5a587bb0e9d5ca13e","value":1}},"ed9cc11bcbe241d58935b3d68df84276":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c3af6c1392340f58efe4d8f9e2456ae","placeholder":"​","style":"IPY_MODEL_3f24ffe215714b4cba7bd40851483a70","value":" 899k/? [00:00&lt;00:00, 7.23MB/s]"}},"6e70172219c84e95ae21b3f7863f45b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22264ddd1a9e483190e376d547c843f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90653f4a15b1444e9008c6771046b5ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"095141f9353442b9a4d498f3c5acd01e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c0b1130d54d044e5a587bb0e9d5ca13e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c3af6c1392340f58efe4d8f9e2456ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f24ffe215714b4cba7bd40851483a70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64d4287b1d9c455fa2e71c1f78e27f7c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27ed51e5856941ca86f3ab5d1baae18d","IPY_MODEL_2dc1c2513ba54f2ea73205e9ab550ba6","IPY_MODEL_1a569899935c4436a20d16d2accd57f3"],"layout":"IPY_MODEL_60770fd7e45b41dda06c834f83592aad"}},"27ed51e5856941ca86f3ab5d1baae18d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3193fbeb758443db403593edf879297","placeholder":"​","style":"IPY_MODEL_a0795c15a76f4b4bbee7e44f721a7b14","value":"Downloading (…)olve/main/merges.txt: "}},"2dc1c2513ba54f2ea73205e9ab550ba6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_14982dbb07c847d99dca3a0a4be061c1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94d8beadeda24929a19a48c0be7f010b","value":1}},"1a569899935c4436a20d16d2accd57f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98b27338fc604f26bad8781fc944e85e","placeholder":"​","style":"IPY_MODEL_c2a291b3f42541bcbcff6504baaab5b0","value":" 456k/? [00:00&lt;00:00, 8.34MB/s]"}},"60770fd7e45b41dda06c834f83592aad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3193fbeb758443db403593edf879297":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0795c15a76f4b4bbee7e44f721a7b14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14982dbb07c847d99dca3a0a4be061c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"94d8beadeda24929a19a48c0be7f010b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98b27338fc604f26bad8781fc944e85e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2a291b3f42541bcbcff6504baaab5b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77f31a72776742c19bb81818c8e36dd4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b6ea4cd37a62442c9286a8627f7004f6","IPY_MODEL_dd97afb6d89d464b93b8fc62a7b01c32","IPY_MODEL_f72253a86a6e488386979b372b2d5e5f"],"layout":"IPY_MODEL_c9d205685c2c466591ab3824c54ba5c4"}},"b6ea4cd37a62442c9286a8627f7004f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c936a8815a414e5cb9d6813e2a577215","placeholder":"​","style":"IPY_MODEL_b8abf5f3af8b4e97b7b3039f4ea9e6c8","value":"Downloading (…)lve/main/config.json: 100%"}},"dd97afb6d89d464b93b8fc62a7b01c32":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf2c28e420394d29bc98289015a0e38b","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9173a2762a6641d19afa388f08bd3777","value":481}},"f72253a86a6e488386979b372b2d5e5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c87a3b7620224ce9b98c90b85b8cf2ab","placeholder":"​","style":"IPY_MODEL_50224ecd71e14d4187f3537623d95f44","value":" 481/481 [00:00&lt;00:00, 23.5kB/s]"}},"c9d205685c2c466591ab3824c54ba5c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c936a8815a414e5cb9d6813e2a577215":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8abf5f3af8b4e97b7b3039f4ea9e6c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf2c28e420394d29bc98289015a0e38b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9173a2762a6641d19afa388f08bd3777":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c87a3b7620224ce9b98c90b85b8cf2ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50224ecd71e14d4187f3537623d95f44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}